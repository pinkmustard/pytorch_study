{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGz_MIIlpX0N"
      },
      "source": [
        "# Ultralytics\n",
        "\n",
        "Ultralytics는 인공 지능 및 기계 학습 분야에서 활동하는 기업으로, 특히 컴퓨터 비전 및 객체 감지 분야에서 널리 인식되고 있습니다. 이 회사는 YOLO (You Only Look Once) 객체 감지 시스템의 다양한 버전들을 개발하고 유지보수하는 데 중요한 역할을 해왔습니다.\n",
        "\n",
        "YOLO는 실시간 객체 감지를 위한 알고리즘으로, 이미지 내에서 객체를 감지하고 분류하는 데 사용됩니다. Ultralytics의 YOLO 구현은 특히 YOLOv3, YOLOv4 및 YOLOv5 버전들과 연관되어 있으며, 이들은 커뮤니티와 산업계에서 널리 사용됩니다.\n",
        "\n",
        "Ultralytics의 YOLO 구현의 특징은 다음과 같습니다:\n",
        "\n",
        "- 고성능: Ultralytics에서 개발되고 있는 YOLO는 높은 정확도와 빠른 처리 속도로 유명합니다. 이는 실시간 비디오 처리 및 대규모 이미지 데이터셋 분석에 매우 유용합니다.\n",
        "\n",
        "- 오픈 소스: Ultralytics는 YOLO 구현을 GitHub를 통해 공개하고 커뮤니티의 기여를 활발히 받고 있습니다. 이는 연구자들과 개발자들이 알고리즘을 쉽게 사용하고 수정할 수 있게 해줍니다.\n",
        "\n",
        "- 지속적인 개발: YOLO 알고리즘은 지속적으로 개선되고 있으며, Ultralytics는 최신 컴퓨터 비전 기술과 알고리즘을 통합하여 성능을 지속적으로 향상시키고 있습니다.\n",
        "\n",
        "Ultralytics의 YOLO 구현은 쉽게 사용할 수 있고, 고도의 사용자 정의가 가능하여 연구와 실제 응용 모두에 매우 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIIPwEYuqaX1"
      },
      "source": [
        "## Ultralytics 설치"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVXUuyFjJfMr",
        "outputId": "2e2bb670-89d1-44c0-ebdd-f6b0090ccd03"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0apZvW7q9QL",
        "outputId": "86acc6a7-2a2c-4961-ef43-475b45d9e9b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.1.5-py3-none-any.whl (702 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m702.8/702.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.1.5\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DDUY7rD5pP7P"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zofiRMt6pP7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5b8cdb-317d-4e2d-c020-698abe612732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 76.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = YOLO('yolov8n.pt') # n, s, m, l, x <-coco dataset 총 80개로 학습 되어있음 울트라디틱스는 알아서 클래스 값을 정해서 해줌"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict('https://file.mk.co.kr/meet/neds/2021/06/image_readtop_2021_560424_16232872624675775.jpg', save=True)"
      ],
      "metadata": {
        "id": "n_rUPA1C523u",
        "outputId": "75394156-719b-4c32-988e-45d7ec028ae0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading https://file.mk.co.kr/meet/neds/2021/06/image_readtop_2021_560424_16232872624675775.jpg to 'image_readtop_2021_560424_16232872624675775.jpg'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 364k/364k [00:00<00:00, 534kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 1/1 /content/image_readtop_2021_560424_16232872624675775.jpg: 448x640 6 persons, 2 buss, 3 handbags, 196.6ms\n",
            "Speed: 14.9ms preprocess, 196.6ms inference, 1559.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 46,  79,  99],\n",
              "         [ 53,  86, 106],\n",
              "         [ 72, 107, 127],\n",
              "         ...,\n",
              "         [240, 213, 163],\n",
              "         [240, 213, 163],\n",
              "         [239, 212, 162]],\n",
              " \n",
              "        [[ 59,  92, 112],\n",
              "         [ 84, 117, 137],\n",
              "         [108, 143, 163],\n",
              "         ...,\n",
              "         [240, 213, 163],\n",
              "         [240, 213, 163],\n",
              "         [240, 213, 163]],\n",
              " \n",
              "        [[100, 132, 155],\n",
              "         [107, 139, 162],\n",
              "         [106, 140, 163],\n",
              "         ...,\n",
              "         [240, 213, 163],\n",
              "         [240, 213, 163],\n",
              "         [240, 213, 163]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 73,  61,  55],\n",
              "         [ 73,  61,  55],\n",
              "         [ 73,  62,  54],\n",
              "         ...,\n",
              "         [146, 126, 108],\n",
              "         [146, 126, 109],\n",
              "         [145, 125, 108]],\n",
              " \n",
              "        [[ 71,  59,  53],\n",
              "         [ 72,  60,  54],\n",
              "         [ 71,  60,  52],\n",
              "         ...,\n",
              "         [139, 122, 103],\n",
              "         [144, 124, 107],\n",
              "         [140, 120, 103]],\n",
              " \n",
              "        [[ 71,  59,  53],\n",
              "         [ 74,  62,  56],\n",
              "         [ 73,  62,  54],\n",
              "         ...,\n",
              "         [132, 115,  96],\n",
              "         [140, 120, 103],\n",
              "         [135, 115,  98]]], dtype=uint8)\n",
              " orig_shape: (854, 1280)\n",
              " path: '/content/image_readtop_2021_560424_16232872624675775.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict'\n",
              " speed: {'preprocess': 14.892339706420898, 'inference': 196.64263725280762, 'postprocess': 1559.7562789916992}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGjFCwO6pP7T",
        "outputId": "e2e4d4e5-bc9d-432b-fbc6-4f7cad0fea0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.5 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=VOC.yaml, epochs=1, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "\n",
            "Dataset 'VOC.yaml' images not found ⚠️, missing path '/content/datasets/VOC/images/test2007'\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/VOCtrainval_06-Nov-2007.zip to '/content/datasets/VOC/images/VOCtrainval_06-Nov-2007.zip'...\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/VOCtest_06-Nov-2007.zip to '/content/datasets/VOC/images/VOCtest_06-Nov-2007.zip'...\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/VOCtrainval_11-May-2012.zip to '/content/datasets/VOC/images/VOCtrainval_11-May-2012.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train2012: 100%|██████████| 5717/5717 [00:01<00:00, 2870.24it/s]\n",
            "val2012: 100%|██████████| 5823/5823 [00:02<00:00, 2014.56it/s]\n",
            "train2007: 100%|██████████| 2501/2501 [00:00<00:00, 3077.60it/s]\n",
            "val2007: 100%|██████████| 2510/2510 [00:00<00:00, 3110.14it/s]\n",
            "test2007: 100%|██████████| 4952/4952 [00:03<00:00, 1278.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ✅ (53.2s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 16.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=20\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    755212  ultralytics.nn.modules.head.Detect           [20, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3014748 parameters, 3014732 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 58/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/VOC/labels/train2007... 16551 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16551/16551 [00:07<00:00, 2124.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/VOC/labels/train2007.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/VOC/labels/test2007... 4952 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4952/4952 [00:07<00:00, 702.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/VOC/labels/test2007.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000417, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      2.52G      1.848      3.139      1.936         38        640: 100%|██████████| 1035/1035 [06:21<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 155/155 [00:53<00:00,  2.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4952      12032      0.499      0.483      0.478      0.297\n",
            "\n",
            "1 epochs completed in 0.124 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.5 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3009548 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 155/155 [00:47<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       4952      12032      0.499      0.483      0.478      0.297\n",
            "             aeroplane       4952        285        0.6      0.442      0.504      0.309\n",
            "               bicycle       4952        337      0.613      0.372      0.471      0.275\n",
            "                  bird       4952        459      0.483      0.418      0.434      0.246\n",
            "                  boat       4952        263      0.486      0.243      0.283       0.16\n",
            "                bottle       4952        469      0.379      0.398      0.345      0.187\n",
            "                   bus       4952        213      0.224      0.751      0.562      0.441\n",
            "                   car       4952       1201      0.771      0.626      0.732      0.514\n",
            "                   cat       4952        358       0.61      0.522       0.59      0.368\n",
            "                 chair       4952        756      0.382      0.344      0.324      0.185\n",
            "                   cow       4952        244      0.513      0.155      0.369      0.247\n",
            "           diningtable       4952        206      0.536      0.567      0.534      0.317\n",
            "                   dog       4952        489       0.34       0.64      0.454      0.275\n",
            "                 horse       4952        348      0.372      0.764      0.625      0.377\n",
            "             motorbike       4952        325      0.555      0.606      0.602      0.361\n",
            "                person       4952       4528       0.71      0.691      0.746      0.456\n",
            "           pottedplant       4952        480      0.415      0.139      0.176     0.0763\n",
            "                 sheep       4952        242      0.371      0.616      0.441      0.302\n",
            "                  sofa       4952        239      0.522      0.383      0.378      0.239\n",
            "                 train       4952        282      0.579       0.55      0.576      0.348\n",
            "             tvmonitor       4952        308      0.519      0.422      0.411      0.255\n",
            "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "results = model.train(data='VOC.yaml', epochs=1, imgsz=640)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfUrDnNXpP7U",
        "outputId": "2b3f6d56-4d42-471d-a455-de0fec186c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://file.mk.co.kr/meet/neds/2021/06/image_readtop_2021_560424_16232872624675775.jpg locally at image_readtop_2021_560424_16232872624675775.jpg\n",
            "image 1/1 /content/image_readtop_2021_560424_16232872624675775.jpg: 448x640 6 persons, 2 buss, 3 handbags, 79.3ms\n",
            "Speed: 5.2ms preprocess, 79.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[ 46,  79,  99],\n",
              "         [ 53,  86, 106],\n",
              "         [ 72, 107, 127],\n",
              "         ...,\n",
              "         [240, 213, 163],\n",
              "         [240, 213, 163],\n",
              "         [239, 212, 162]],\n",
              " \n",
              "        [[ 59,  92, 112],\n",
              "         [ 84, 117, 137],\n",
              "         [108, 143, 163],\n",
              "         ...,\n",
              "         [240, 213, 163],\n",
              "         [240, 213, 163],\n",
              "         [240, 213, 163]],\n",
              " \n",
              "        [[100, 132, 155],\n",
              "         [107, 139, 162],\n",
              "         [106, 140, 163],\n",
              "         ...,\n",
              "         [240, 213, 163],\n",
              "         [240, 213, 163],\n",
              "         [240, 213, 163]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 73,  61,  55],\n",
              "         [ 73,  61,  55],\n",
              "         [ 73,  62,  54],\n",
              "         ...,\n",
              "         [146, 126, 108],\n",
              "         [146, 126, 109],\n",
              "         [145, 125, 108]],\n",
              " \n",
              "        [[ 71,  59,  53],\n",
              "         [ 72,  60,  54],\n",
              "         [ 71,  60,  52],\n",
              "         ...,\n",
              "         [139, 122, 103],\n",
              "         [144, 124, 107],\n",
              "         [140, 120, 103]],\n",
              " \n",
              "        [[ 71,  59,  53],\n",
              "         [ 74,  62,  56],\n",
              "         [ 73,  62,  54],\n",
              "         ...,\n",
              "         [132, 115,  96],\n",
              "         [140, 120, 103],\n",
              "         [135, 115,  98]]], dtype=uint8)\n",
              " orig_shape: (854, 1280)\n",
              " path: '/content/image_readtop_2021_560424_16232872624675775.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/train2'\n",
              " speed: {'preprocess': 5.211353302001953, 'inference': 79.28085327148438, 'postprocess': 1.7104148864746094}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.predict('https://file.mk.co.kr/meet/neds/2021/06/image_readtop_2021_560424_16232872624675775.jpg', save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eLBkwf0rpP7U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}